{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "import os, time, random, threading, h5py, math,pickle, sys\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterServer:\n",
    "    def __init__(self, sess, log_dir, networksetting, parameters):\n",
    "        self.sess = sess\n",
    "        self.parameters = parameters\n",
    "        with tf.variable_scope(\"parameter_server\", reuse=tf.AUTO_REUSE):\n",
    "            self.state1_ = tf.placeholder(tf.float32, shape=(None,) + self.parameters.resolution)\n",
    "            self.q_value, self.conv1, self.conv2, self.q_prob = self._build_model(self.state1_, networksetting)\n",
    "\n",
    "        self.weights_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"parameter_server\")\n",
    "#         self.optimizer = tf.train.RMSPropOptimizer(LEARNING_RATE, RMSProbDecaly)\n",
    "        self.optimizer = tf.train.AdamOptimizer()\n",
    "            \n",
    "        with tf.variable_scope(\"summary\", reuse=tf.AUTO_REUSE):\n",
    "            self._build_summary(sess,log_dir)\n",
    "        \n",
    "        self.saver = tf.train.Saver(max_to_keep = 20)\n",
    "    \n",
    "\n",
    "    def _build_model(self,state,networksetting):\n",
    "            conv1 = networksetting.conv1(state)\n",
    "            maxpool1 = networksetting.maxpool1(conv1)\n",
    "            conv2 = networksetting.conv2(maxpool1)\n",
    "            maxpool2 = networksetting.maxpool2(conv2)\n",
    "            reshape = networksetting.reshape(maxpool2)\n",
    "            fc1 = networksetting.fc1(reshape)\n",
    "            q = networksetting.q_value(fc1)\n",
    "            \n",
    "            q_prob = tf.nn.softmax(q)\n",
    "                \n",
    "            print(\"---------MODEL SHAPE-------------\")\n",
    "            print(state.get_shape())\n",
    "            print(conv1.get_shape())\n",
    "            print(maxpool1.get_shape())\n",
    "            print(conv2.get_shape())\n",
    "            print(maxpool2.get_shape())\n",
    "            print(reshape.get_shape())\n",
    "            print(fc1.get_shape())\n",
    "            print(q.get_shape())\n",
    "            \n",
    "            return q, conv1, conv2, q_prob\n",
    "                \n",
    "    def _build_summary(self,sess, log_dir):\n",
    "        \n",
    "        self.reward_ = tf.placeholder(tf.float32,shape=(), name=\"reward\")\n",
    "        self.frag_ = tf.placeholder(tf.float32, shape=(), name=\"frag\")\n",
    "        self.death_ = tf.placeholder(tf.float32, shape=(), name=\"death\")\n",
    "        self.kill_ = tf.placeholder(tf.float32, shape=(), name=\"kill\")\n",
    "        self.score_step_ = tf.placeholder(tf.float32, shape=(), name=\"step\")\n",
    "        self.score_processtime_ = tf.placeholder(tf.float32, shape=(), name=\"score_processtime\")\n",
    "        self.loss_one_ = tf.placeholder(tf.float32, shape=(), name=\"loss_one\")\n",
    "        self.loss_adv_ = tf.placeholder(tf.float32, shape=(), name=\"loss_adv\")\n",
    "        self.loss_cls_ = tf.placeholder(tf.float32, shape=(), name=\"loss_class\")\n",
    "        self.loss_l2_ = tf.placeholder(tf.float32, shape=(), name=\"loss_l2\")\n",
    "        self.loss_processtime_ = tf.placeholder(tf.float32, shape=(), name=\"loss_processtime\")\n",
    "        \n",
    "        with tf.variable_scope(\"Summary_Score\"):\n",
    "            s = [tf.summary.scalar('reward', self.reward_, family=\"score\"), tf.summary.scalar('frag', self.frag_, family=\"score\"), \\\n",
    "                 tf.summary.scalar(\"death\", self.death_, family=\"score\"),\n",
    "                 tf.summary.scalar(\"kill\", self.kill_, family=\"score\"), \\\n",
    "                 tf.summary.scalar(\"step\",self.score_step_, family=\"score\"), \n",
    "                 tf.summary.scalar(\"score_processtime\", self.score_processtime_, family=\"score\")]\n",
    "            self.summary_reward = tf.summary.merge(s)\n",
    "        \n",
    "        with tf.variable_scope(\"Summary_Loss\"):\n",
    "            list_summary = [tf.summary.scalar('loss_onestep', self.loss_one_, family=\"loss\"), \n",
    "                            tf.summary.scalar('loss_advantage', self.loss_adv_, family=\"loss\"),\n",
    "                            tf.summary.scalar('loss_class', self.loss_cls_, family=\"loss\"),\n",
    "                            tf.summary.scalar('loss_l2', self.loss_l2_, family='loss'),\n",
    "                            tf.summary.scalar('loss_processtime', self.loss_processtime_, family=\"loss\")]\n",
    "            self.summary_loss = tf.summary.merge(list_summary)\n",
    "        \n",
    "#         with tf.variable_scope(\"Summary_Images\"):\n",
    "#             conv1_display = tf.reshape(tf.transpose(self.conv1, [0,1,4,2,3]), (-1, self.conv1.get_shape()[1],self.conv1.get_shape()[2]))\n",
    "#             conv2_display = tf.reshape(tf.transpose(self.conv2, [0,1,4,2,3]), (-1, self.conv2.get_shape()[1],self.conv2.get_shape()[2]))\n",
    "#             conv1_display = tf.expand_dims(conv1_display, -1)\n",
    "#             conv2_display = tf.expand_dims(conv2_display, -1)\n",
    "\n",
    "#             state_shape = self.state1_.get_shape()\n",
    "#             conv1_shape = conv1_display.get_shape()\n",
    "#             conv2_shape = conv2_display.get_shape()\n",
    "\n",
    "#             s_img = []\n",
    "#             s_img.append(tf.summary.image('state',tf.reshape(self.state1_,[-1, state_shape[2], state_shape[3], state_shape[4]]), 1, family=\"state1\"))\n",
    "#             s_img.append(tf.summary.image('conv1',tf.reshape(self.conv1,[-1, conv1_shape[1], conv1_shape[2], 1]), family=\"conv1\"))\n",
    "#             s_img.append(tf.summary.image('conv2',tf.reshape(self.conv2,[-1, conv2_shape[1], conv2_shape[2], 1]), family=\"conv2\"))\n",
    "\n",
    "#             self.summary_image = tf.summary.merge(s_img)\n",
    "            \n",
    "        with tf.variable_scope(\"Summary_Weights\"):\n",
    "            s = [tf.summary.histogram(values=w, name=w.name, family=\"weights\") for w in self.weights_params]\n",
    "            self.summary_weights = tf.summary.merge(s)\n",
    "\n",
    "        self.writer = tf.summary.FileWriter(log_dir)\n",
    "        \n",
    "    def write_graph(self, sess):\n",
    "        self.writer.add_graph(sess.graph)\n",
    "        \n",
    "    def write_score(self,sess, step ,reward, frag, death, kill, score_step, processtime):\n",
    "        m = sess.run(self.summary_reward, feed_dict={self.reward_:reward, self.frag_:frag, self.death_:death, self.kill_:kill, self.score_step_:score_step, self.score_processtime_:processtime})\n",
    "        return self.writer.add_summary(m, step)\n",
    "    \n",
    "    def write_loss(self,sess, step, l_o, l_n,l_c, l_l, process_time):\n",
    "        m = sess.run(self.summary_loss, feed_dict={self.loss_one_: l_o, self.loss_adv_:l_n, self.loss_cls_:l_c, self.loss_l2_:l_l, self.loss_processtime_:processtime})\n",
    "        return self.writer.add_summary(m, step)\n",
    "    \n",
    "#     def write_img(self,sess, step, state):\n",
    "#         m = sess.run(self.summary_image, feed_dict={self.state1_: state})\n",
    "#         return self.writer.add_summary(m, step)\n",
    "    \n",
    "    def write_weights(self, sess, step):\n",
    "        m = sess.run(self.summary_weights)\n",
    "        return self.writer.add_summary(m, step)\n",
    "        \n",
    "    def load_model(self, sess, model_path, step):\n",
    "        self.saver.restore(sess, model_path+'-'+str(step))\n",
    "    \n",
    "    def save_model(self, sess,  model_path, step):\n",
    "        self.saver.save(sess, model_path, global_step = step)\n",
    "        \n",
    "    def load_cnnweights(self, sess, weights_path):\n",
    "        assert len(weights_path) == 4\n",
    "        cnn_weights = self.weights_params[:4]\n",
    "        w_demo = [np.load(w_p) for w_p in weights_path]\n",
    "        plh = [tf.placeholder(tf.float32, shape=w.shape) for w in w_demo]\n",
    "        assign_op = [w.assign(p) for w, p in zip(cnn_weights, plh)]\n",
    "        feed_dict = {p:w for w,p in zip(w_demo, plh)}\n",
    "        sess.run(assign_op, feed_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
