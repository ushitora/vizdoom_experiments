{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    \n",
    "    def __init__(self, network):\n",
    "        self.network = network\n",
    "        \n",
    "        self.obs = {}\n",
    "        self.obs['s1'] = np.zeros((N_ADV, )+ RESOLUTION, dtype=np.float32)\n",
    "        \n",
    "        self.states_buff = np.zeros((N_ADV*3-2,) + RESOLUTION, dtype=np.float32)\n",
    "        self.rewards_buff = np.zeros((N_ADV*2-1,), dtype=np.float32)\n",
    "        self.actions_buff = np.zeros((N_ADV*2-1, ), dtype=np.float32)\n",
    "        self.isterminals_buff = np.ones((N_ADV*2-1, ), dtype=np.float32)\n",
    "        self.buff_pointer = 0\n",
    "        \n",
    "    def calc_eps(self, progress):\n",
    "        if progress < 0.2:\n",
    "            return EPS_MIN\n",
    "        elif progress >= 0.2 and progress < 0.8:\n",
    "            return ((EPS_MAX - EPS_MIN)/ 0.6) * progress + ( EPS_MIN -  (EPS_MAX - EPS_MIN)/ 0.6 * 0.2)\n",
    "        else :\n",
    "            return EPS_MAX\n",
    "\n",
    "    def act_eps_greedy(self, sess, s1, progress):\n",
    "        assert progress >= 0.0 and progress <=1.0\n",
    "        \n",
    "        self.push_obs(s1)\n",
    "        eps = self.calc_eps(progress)\n",
    "        if random.random() <= eps:\n",
    "            p = self.network.get_policy(sess, [self.obs['s1']])\n",
    "            a_idx = np.random.choice(N_AGENT_ACTION, p=p)\n",
    "        else:\n",
    "            a_idx = np.random.randint(N_AGENT_ACTION)\n",
    "            \n",
    "        return a_idx\n",
    "    \n",
    "    def act_greedy(self, sess, s1):\n",
    "        p = self.network.get_policy(sess, [self.obs['s1']])[0]\n",
    "        a_idx = np.random.choice(N_AGENT_ACTION, p=p)\n",
    "        return a_idx\n",
    "    \n",
    "    def get_gradients(self, sess):\n",
    "        return self.network.get_gradients(sess, self.batch['s1'], self.batch['action'], self.batch['reward'], self.batch['isterminal'])\n",
    "    \n",
    "    def train_network(self, sess):\n",
    "        batch={'s1':[], 'actions':[], 'rewards':[], 'isterminals':[]}\n",
    "        for i in range(N_ADV):\n",
    "            batch['s1'].append(self.states_buff[i:i+N_ADV])\n",
    "            batch['actions'].append(self.actions_buff[i])\n",
    "            batch['isterminals'].append(self.isterminals_buff[i])\n",
    "            batch['rewards'].append(sum([r*GAMMA**j for j,r in self.rewards_buff[i:i+N_ADV]]))\n",
    "        return self.network.train_network(sess, batch['s1'], batch['actions'], batch['rewards'], batch['isterminals'])\n",
    "    \n",
    "    def push_obs(self, s1):\n",
    "        self.obs['s1'] = np.roll(self.obs['s1'],shift=-1, axis=0)\n",
    "        self.obs['s1'][-1] = s1\n",
    "        \n",
    "    def clear_obs(self):\n",
    "        self.obs = {}\n",
    "        self.obs['s1'] = np.zeros((N_ADV,)+ RESOLUTION, dtype=np.float32)\n",
    "        \n",
    "    def push_batch(self, s1, action, reward, isterminal):\n",
    "        self.states_buff = np.roll(self.states_buff, shift=-1, axis=0)\n",
    "        self.actions_buff = np.roll(self.actions_buff, shift=-1, axis=0)\n",
    "        self.rewards_buff = np.roll(self.rewards_buff, shift=-1, axis=0)\n",
    "        self.isterminals_buff = np.roll(self.isterminals_buff, shift=-1, axis=0)\n",
    "        self.states_buff[-1] = s1\n",
    "        self.actions_buff[-1] = action\n",
    "        self.rewards_buff[-1] = reward\n",
    "        self.isterminals_buff[-1] = isterminal\n",
    "        self.buff_pointer += 1\n",
    "    \n",
    "    def clear_batch(self):\n",
    "        self.states_buff = np.zeros((N_ADV*3-2,) + RESOLUTION, dtype=np.float32)\n",
    "        self.rewards_buff = np.zeros((N_ADV*2-1,), dtype=np.float32)\n",
    "        self.actions_buff = np.zeros((N_ADV*2-1, ), dtype=np.float32)\n",
    "        self.isterminals_buff = np.ones((N_ADV*2-1, ), dtype=np.float32)\n",
    "        self.buff_pointer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
